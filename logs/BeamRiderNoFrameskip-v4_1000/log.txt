Logging to /home/brendan/PycharmProjects/honours/logs/BeamRiderNoFrameskip-v4_1000
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 100      |
| mean 100 episode reward | 2.9      |
| steps                   | 43808    |
--------------------------------------
Saving model due to mean reward increase: None -> 2.9
Saving model due to mean reward increase: 2.9 -> 3.0
Saving model due to mean reward increase: 3.0 -> 3.1
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 200      |
| mean 100 episode reward | 3        |
| steps                   | 89169    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 300      |
| mean 100 episode reward | 2.6      |
| steps                   | 133155   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 400      |
| mean 100 episode reward | 3        |
| steps                   | 181508   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 500      |
| mean 100 episode reward | 3.2      |
| steps                   | 233519   |
--------------------------------------
Saving model due to mean reward increase: 3.1 -> 3.2
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 600      |
| mean 100 episode reward | 3.1      |
| steps                   | 290068   |
--------------------------------------
Saving model due to mean reward increase: 3.2 -> 3.4
Saving model due to mean reward increase: 3.4 -> 3.8
Saving model due to mean reward increase: 3.8 -> 4.0
Saving model due to mean reward increase: 4.0 -> 4.1
Saving model due to mean reward increase: 4.1 -> 4.3
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 700      |
| mean 100 episode reward | 4.4      |
| steps                   | 364887   |
--------------------------------------
Saving model due to mean reward increase: 4.3 -> 4.4
Saving model due to mean reward increase: 4.4 -> 4.7
Saving model due to mean reward increase: 4.7 -> 4.8
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 800      |
| mean 100 episode reward | 3.8      |
| steps                   | 423976   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 900      |
| mean 100 episode reward | 2.9      |
| steps                   | 481471   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1000     |
| mean 100 episode reward | 2.8      |
| steps                   | 532895   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1100     |
| mean 100 episode reward | 3.3      |
| steps                   | 588961   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1200     |
| mean 100 episode reward | 3.9      |
| steps                   | 645421   |
--------------------------------------
Saving model due to mean reward increase: 4.8 -> 5.0
Saving model due to mean reward increase: 5.0 -> 5.1
Saving model due to mean reward increase: 5.1 -> 5.6
Saving model due to mean reward increase: 5.6 -> 6.0
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1300     |
| mean 100 episode reward | 5.8      |
| steps                   | 712459   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1400     |
| mean 100 episode reward | 5        |
| steps                   | 769543   |
--------------------------------------
Saving model due to mean reward increase: 6.0 -> 6.1
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1500     |
| mean 100 episode reward | 6.1      |
| steps                   | 832569   |
--------------------------------------
Saving model due to mean reward increase: 6.1 -> 6.6
Saving model due to mean reward increase: 6.6 -> 6.9
Saving model due to mean reward increase: 6.9 -> 7.3
Saving model due to mean reward increase: 7.3 -> 7.4
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1600     |
| mean 100 episode reward | 7.3      |
| steps                   | 900269   |
--------------------------------------
Saving model due to mean reward increase: 7.4 -> 7.5
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1700     |
| mean 100 episode reward | 6.5      |
| steps                   | 967543   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1800     |
| mean 100 episode reward | 6.4      |
| steps                   | 1037512  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1900     |
| mean 100 episode reward | 6.8      |
| steps                   | 1099713  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2000     |
| mean 100 episode reward | 5.7      |
| steps                   | 1174429  |
--------------------------------------
Saving model due to mean reward increase: 7.5 -> 7.6
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2100     |
| mean 100 episode reward | 7.7      |
| steps                   | 1243732  |
--------------------------------------
Saving model due to mean reward increase: 7.6 -> 7.8
Saving model due to mean reward increase: 7.8 -> 8.1
Saving model due to mean reward increase: 8.1 -> 8.4
Saving model due to mean reward increase: 8.4 -> 8.5
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2200     |
| mean 100 episode reward | 8.5      |
| steps                   | 1315137  |
--------------------------------------
Saving model due to mean reward increase: 8.5 -> 8.6
Saving model due to mean reward increase: 8.6 -> 9.2
Saving model due to mean reward increase: 9.2 -> 9.6
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2300     |
| mean 100 episode reward | 9.7      |
| steps                   | 1391203  |
--------------------------------------
Saving model due to mean reward increase: 9.6 -> 10.0
Saving model due to mean reward increase: 10.0 -> 10.1
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2400     |
| mean 100 episode reward | 9.4      |
| steps                   | 1469820  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2500     |
| mean 100 episode reward | 9.6      |
| steps                   | 1550995  |
--------------------------------------
Saving model due to mean reward increase: 10.1 -> 10.4
Saving model due to mean reward increase: 10.4 -> 10.7
Saving model due to mean reward increase: 10.7 -> 10.8
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2600     |
| mean 100 episode reward | 10.4     |
| steps                   | 1632688  |
--------------------------------------
Saving model due to mean reward increase: 10.8 -> 11.4
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2700     |
| mean 100 episode reward | 11.5     |
| steps                   | 1716649  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2800     |
| mean 100 episode reward | 9.1      |
| steps                   | 1785387  |
--------------------------------------
Saving model due to mean reward increase: 11.4 -> 11.5
Saving model due to mean reward increase: 11.5 -> 11.7
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2900     |
| mean 100 episode reward | 11.8     |
| steps                   | 1871235  |
--------------------------------------
Saving model due to mean reward increase: 11.7 -> 12.2
Saving model due to mean reward increase: 12.2 -> 12.3
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3000     |
| mean 100 episode reward | 12.5     |
| steps                   | 1959371  |
--------------------------------------
Saving model due to mean reward increase: 12.3 -> 12.7
Saving model due to mean reward increase: 12.7 -> 12.9
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3100     |
| mean 100 episode reward | 12.3     |
| steps                   | 2046958  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3200     |
| mean 100 episode reward | 12       |
| steps                   | 2128490  |
--------------------------------------
Saving model due to mean reward increase: 12.9 -> 13.2
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3300     |
| mean 100 episode reward | 13       |
| steps                   | 2218080  |
--------------------------------------
Saving model due to mean reward increase: 13.2 -> 13.8
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3400     |
| mean 100 episode reward | 12.6     |
| steps                   | 2301213  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3500     |
| mean 100 episode reward | 13       |
| steps                   | 2387017  |
--------------------------------------
Saving model due to mean reward increase: 13.8 -> 14.0
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3600     |
| mean 100 episode reward | 12.3     |
| steps                   | 2468877  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3700     |
| mean 100 episode reward | 11.9     |
| steps                   | 2556912  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3800     |
| mean 100 episode reward | 12.9     |
| steps                   | 2641542  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3900     |
| mean 100 episode reward | 11.7     |
| steps                   | 2721604  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 4000     |
| mean 100 episode reward | 12       |
| steps                   | 2809130  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 4100     |
| mean 100 episode reward | 12.5     |
| steps                   | 2891582  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 4200     |
| mean 100 episode reward | 11.5     |
| steps                   | 2970552  |
--------------------------------------
Restored model with mean reward: 14.0
