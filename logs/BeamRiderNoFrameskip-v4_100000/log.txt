Logging to /home/brendan/PycharmProjects/honours/logs/BeamRiderNoFrameskip-v4_100000
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 100      |
| mean 100 episode reward | 2.5      |
| steps                   | 41147    |
--------------------------------------
Saving model due to mean reward increase: None -> 2.6
Saving model due to mean reward increase: 2.6 -> 2.9
Saving model due to mean reward increase: 2.9 -> 3.0
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 200      |
| mean 100 episode reward | 3.1      |
| steps                   | 89425    |
--------------------------------------
Saving model due to mean reward increase: 3.0 -> 3.1
Saving model due to mean reward increase: 3.1 -> 3.3
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 300      |
| mean 100 episode reward | 3.4      |
| steps                   | 142401   |
--------------------------------------
Saving model due to mean reward increase: 3.3 -> 3.6
Saving model due to mean reward increase: 3.6 -> 3.9
Saving model due to mean reward increase: 3.9 -> 4.2
Saving model due to mean reward increase: 4.2 -> 4.5
Saving model due to mean reward increase: 4.5 -> 4.9
Saving model due to mean reward increase: 4.9 -> 5.3
Saving model due to mean reward increase: 5.3 -> 5.6
Saving model due to mean reward increase: 5.6 -> 5.9
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 400      |
| mean 100 episode reward | 6.2      |
| steps                   | 226339   |
--------------------------------------
Saving model due to mean reward increase: 5.9 -> 6.4
Saving model due to mean reward increase: 6.4 -> 7.0
Saving model due to mean reward increase: 7.0 -> 7.7
Saving model due to mean reward increase: 7.7 -> 8.2
Saving model due to mean reward increase: 8.2 -> 9.1
Saving model due to mean reward increase: 9.1 -> 9.5
Saving model due to mean reward increase: 9.5 -> 10.4
Saving model due to mean reward increase: 10.4 -> 11.0
Saving model due to mean reward increase: 11.0 -> 11.7
Saving model due to mean reward increase: 11.7 -> 12.5
Saving model due to mean reward increase: 12.5 -> 13.2
Saving model due to mean reward increase: 13.2 -> 14.1
Saving model due to mean reward increase: 14.1 -> 15.0
Saving model due to mean reward increase: 15.0 -> 15.4
Saving model due to mean reward increase: 15.4 -> 16.3
Saving model due to mean reward increase: 16.3 -> 16.8
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 500      |
| mean 100 episode reward | 17.3     |
| steps                   | 383280   |
--------------------------------------
Saving model due to mean reward increase: 16.8 -> 17.2
Saving model due to mean reward increase: 17.2 -> 18.0
Saving model due to mean reward increase: 18.0 -> 18.1
Saving model due to mean reward increase: 18.1 -> 18.8
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 600      |
| mean 100 episode reward | 18.2     |
| steps                   | 526986   |
--------------------------------------
Saving model due to mean reward increase: 18.8 -> 19.4
Saving model due to mean reward increase: 19.4 -> 20.1
Saving model due to mean reward increase: 20.1 -> 20.4
Saving model due to mean reward increase: 20.4 -> 20.9
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 700      |
| mean 100 episode reward | 19.1     |
| steps                   | 652300   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 800      |
| mean 100 episode reward | 18       |
| steps                   | 772716   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 900      |
| mean 100 episode reward | 19.2     |
| steps                   | 896205   |
--------------------------------------
Saving model due to mean reward increase: 20.9 -> 21.3
Saving model due to mean reward increase: 21.3 -> 21.6
Saving model due to mean reward increase: 21.6 -> 22.3
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1000     |
| mean 100 episode reward | 21       |
| steps                   | 1023701  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1100     |
| mean 100 episode reward | 16.8     |
| steps                   | 1137246  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1200     |
| mean 100 episode reward | 22.3     |
| steps                   | 1271805  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1300     |
| mean 100 episode reward | 14.8     |
| steps                   | 1365563  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1400     |
| mean 100 episode reward | 19.3     |
| steps                   | 1483816  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1500     |
| mean 100 episode reward | 19.4     |
| steps                   | 1604754  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1600     |
| mean 100 episode reward | 19.6     |
| steps                   | 1722420  |
--------------------------------------
Saving model due to mean reward increase: 22.3 -> 22.5
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1700     |
| mean 100 episode reward | 21.2     |
| steps                   | 1845421  |
--------------------------------------
Saving model due to mean reward increase: 22.5 -> 22.7
Saving model due to mean reward increase: 22.7 -> 23.4
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1800     |
| mean 100 episode reward | 22.4     |
| steps                   | 1969372  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1900     |
| mean 100 episode reward | 18.1     |
| steps                   | 2077830  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2000     |
| mean 100 episode reward | 22       |
| steps                   | 2203348  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2100     |
| mean 100 episode reward | 16.6     |
| steps                   | 2301291  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2200     |
| mean 100 episode reward | 19.8     |
| steps                   | 2415007  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2300     |
| mean 100 episode reward | 23.5     |
| steps                   | 2548333  |
--------------------------------------
Saving model due to mean reward increase: 23.4 -> 23.6
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2400     |
| mean 100 episode reward | 22.3     |
| steps                   | 2671465  |
--------------------------------------
Saving model due to mean reward increase: 23.6 -> 23.8
Saving model due to mean reward increase: 23.8 -> 24.2
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2500     |
| mean 100 episode reward | 23.7     |
| steps                   | 2800132  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2600     |
| mean 100 episode reward | 20.2     |
| steps                   | 2915729  |
--------------------------------------
Restored model with mean reward: 24.2
