Logging to /home/brendan/PycharmProjects/honours/logs_PongNoFrameskip-v4_10000
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 100      |
| mean 100 episode reward | -20      |
| steps                   | 96089    |
--------------------------------------
Saving model due to mean reward increase: None -> -20.0
Saving model due to mean reward increase: -20.0 -> -19.9
Saving model due to mean reward increase: -19.9 -> -19.8
Saving model due to mean reward increase: -19.8 -> -19.7
Saving model due to mean reward increase: -19.7 -> -19.6
Saving model due to mean reward increase: -19.6 -> -19.4
Saving model due to mean reward increase: -19.4 -> -19.2
Saving model due to mean reward increase: -19.2 -> -19.0
Saving model due to mean reward increase: -19.0 -> -18.8
Saving model due to mean reward increase: -18.8 -> -18.6
Saving model due to mean reward increase: -18.6 -> -18.3
Saving model due to mean reward increase: -18.3 -> -18.2
Saving model due to mean reward increase: -18.2 -> -17.9
Saving model due to mean reward increase: -17.9 -> -17.8
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 200      |
| mean 100 episode reward | -17.8    |
| steps                   | 241475   |
--------------------------------------
Saving model due to mean reward increase: -17.8 -> -17.7
Saving model due to mean reward increase: -17.7 -> -17.6
Saving model due to mean reward increase: -17.6 -> -17.3
Saving model due to mean reward increase: -17.3 -> -17.1
Saving model due to mean reward increase: -17.1 -> -16.8
Saving model due to mean reward increase: -16.8 -> -16.5
Saving model due to mean reward increase: -16.5 -> -15.9
Saving model due to mean reward increase: -15.9 -> -15.5
Saving model due to mean reward increase: -15.5 -> -15.0
Saving model due to mean reward increase: -15.0 -> -14.5
Saving model due to mean reward increase: -14.5 -> -13.9
Saving model due to mean reward increase: -13.9 -> -13.0
Saving model due to mean reward increase: -13.0 -> -11.7
Saving model due to mean reward increase: -11.7 -> -10.0
Saving model due to mean reward increase: -10.0 -> -8.2
Saving model due to mean reward increase: -8.2 -> -6.2
Saving model due to mean reward increase: -6.2 -> -4.0
Saving model due to mean reward increase: -4.0 -> -2.5
Saving model due to mean reward increase: -2.5 -> -0.7
Saving model due to mean reward increase: -0.7 -> 1.4
Saving model due to mean reward increase: 1.4 -> 3.1
Saving model due to mean reward increase: 3.1 -> 5.2
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 300      |
| mean 100 episode reward | 6.6      |
| steps                   | 466745   |
--------------------------------------
Saving model due to mean reward increase: 5.2 -> 6.9
Saving model due to mean reward increase: 6.9 -> 8.9
Saving model due to mean reward increase: 8.9 -> 10.6
Saving model due to mean reward increase: 10.6 -> 12.1
Saving model due to mean reward increase: 12.1 -> 14.0
Saving model due to mean reward increase: 14.0 -> 15.1
Saving model due to mean reward increase: 15.1 -> 16.3
Saving model due to mean reward increase: 16.3 -> 17.6
Saving model due to mean reward increase: 17.6 -> 18.2
Saving model due to mean reward increase: 18.2 -> 18.3
Saving model due to mean reward increase: 18.3 -> 18.5
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 400      |
| mean 100 episode reward | 18.4     |
| steps                   | 651906   |
--------------------------------------
Saving model due to mean reward increase: 18.5 -> 18.6
Saving model due to mean reward increase: 18.6 -> 18.7
Saving model due to mean reward increase: 18.7 -> 18.9
Saving model due to mean reward increase: 18.9 -> 19.0
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 500      |
| mean 100 episode reward | 19       |
| steps                   | 833379   |
--------------------------------------
Saving model due to mean reward increase: 19.0 -> 19.1
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 600      |
| mean 100 episode reward | 19       |
| steps                   | 1015201  |
--------------------------------------
Saving model due to mean reward increase: 19.1 -> 19.2
Saving model due to mean reward increase: 19.2 -> 19.3
Saving model due to mean reward increase: 19.3 -> 19.4
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 700      |
| mean 100 episode reward | 19.4     |
| steps                   | 1193033  |
--------------------------------------
Saving model due to mean reward increase: 19.4 -> 19.5
Saving model due to mean reward increase: 19.5 -> 19.6
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 800      |
| mean 100 episode reward | 19.2     |
| steps                   | 1372828  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 900      |
| mean 100 episode reward | 19.2     |
| steps                   | 1553623  |
--------------------------------------
Saving model due to mean reward increase: 19.6 -> 19.7
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1000     |
| mean 100 episode reward | 19.8     |
| steps                   | 1727785  |
--------------------------------------
Saving model due to mean reward increase: 19.7 -> 19.8
Saving model due to mean reward increase: 19.8 -> 20.0
Saving model due to mean reward increase: 20.0 -> 20.1
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1100     |
| mean 100 episode reward | 20       |
| steps                   | 1900196  |
--------------------------------------
Saving model due to mean reward increase: 20.1 -> 20.2
Saving model due to mean reward increase: 20.2 -> 20.3
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1200     |
| mean 100 episode reward | 20.3     |
| steps                   | 2070859  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1300     |
| mean 100 episode reward | 20.1     |
| steps                   | 2243872  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1400     |
| mean 100 episode reward | 20.1     |
| steps                   | 2415276  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1500     |
| mean 100 episode reward | 20.2     |
| steps                   | 2586320  |
--------------------------------------
Saving model due to mean reward increase: 20.3 -> 20.5
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1600     |
| mean 100 episode reward | 20.5     |
| steps                   | 2757137  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1700     |
| mean 100 episode reward | 20.3     |
| steps                   | 2928302  |
--------------------------------------
Restored model with mean reward: 20.5
